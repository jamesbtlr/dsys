---
phase: 01-schema-contracts
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - skills/dsys/references/analysis-rubric.md
  - skills/dsys/references/analysis-findings-schema.md
  - skills/dsys/schemas/analysis-findings.schema.json
autonomous: true
requirements:
  - ORCH-04

must_haves:
  truths:
    - "The analysis findings JSON Schema validates a conformant UI screenshot analysis output"
    - "The analysis findings JSON Schema validates a conformant visual reference analysis output"
    - "The analysis findings JSON Schema rejects output missing required fields"
    - "The extraction rubric specifies exact quantization rules for spacing, type sizes, border radius, and colors"
    - "The analysis findings schema distinguishes ui_screenshot from visual_reference with different required fields per type"
  artifacts:
    - path: "skills/dsys/references/analysis-rubric.md"
      provides: "Extraction instructions for the analyzer agent"
      contains: "Quantization Rules"
    - path: "skills/dsys/references/analysis-findings-schema.md"
      provides: "Human-readable spec of analysis output structure with fill-in template"
      contains: "image_type"
    - path: "skills/dsys/schemas/analysis-findings.schema.json"
      provides: "Machine-readable JSON Schema 2020-12 for analysis findings"
      contains: "$schema"
  key_links:
    - from: "skills/dsys/references/analysis-rubric.md"
      to: "skills/dsys/schemas/analysis-findings.schema.json"
      via: "Rubric instructs what to extract; schema enforces the output structure"
      pattern: "analysis-findings"
    - from: "skills/dsys/references/analysis-findings-schema.md"
      to: "skills/dsys/schemas/analysis-findings.schema.json"
      via: "Human-readable spec mirrors the machine-readable schema exactly"
      pattern: "image_type"
---

<objective>
Create the analysis agent's input/output contracts: the extraction rubric that tells the analyzer what to look for in screenshots, the human-readable analysis findings spec, and the machine-readable JSON Schema that validates analyzer output.

Purpose: The analysis agent (Phase 2) must have an unambiguous contract defining what it extracts and how it structures its output. Without these documents, the analyzer would produce freeform output that downstream agents cannot consume reliably.

Output: Three files in `skills/dsys/` — the extraction rubric, the human-readable findings spec with an embedded fill-in JSON template, and the formal JSON Schema 2020-12 file.
</objective>

<execution_context>
@/Users/james/.claude/get-shit-done/workflows/execute-plan.md
@/Users/james/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-schema-contracts/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create extraction rubric and analysis findings human-readable spec</name>
  <files>
    skills/dsys/references/analysis-rubric.md
    skills/dsys/references/analysis-findings-schema.md
  </files>
  <action>
Create two Markdown documents in `skills/dsys/references/`.

**File 1: `analysis-rubric.md`** — The extraction rubric that will be embedded in the analyzer agent's prompt. Must contain:

1. **Image Classification** section:
   - How to distinguish `ui_screenshot` from `visual_reference`
   - `ui_screenshot`: contains recognizable UI elements (buttons, inputs, navigation, cards, tables, text blocks in a layout)
   - `visual_reference`: mood photos, brand assets, illustrations, abstract art, nature photos, anything without UI structure
   - When ambiguous, classify as `visual_reference` (conservative — avoid extracting fake UI tokens from non-UI images)

2. **What to Extract — UI Screenshots** section:
   - **Colors**: Extract the dominant color palette. Identify semantic roles from visual context (what color is used for buttons → action.primary, what color is the page background → surface.default, what color is body text → text.primary). Do NOT round hex values. Infer the "intended" palette color from context — if a button is almost-but-not-quite #3B82F6, it's probably #3B82F6.
   - **Typography**: Identify font families (sans, mono, display). Snap observed sizes to the standard type scale: 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 28, 32, 36, 40, 48, 56, 64, 72, 80, 96. Identify weight usage patterns (which weights appear for headings vs body vs UI labels). Classify line-height pattern as tight/normal/relaxed/loose.
   - **Spacing**: Snap all observed spacing to the 4px grid: 4, 8, 12, 16, 20, 24, 32, 40, 48, 64, 80, 96, 128. Values < 2px → ignore. Classify overall density as compact/comfortable/spacious. Identify the base unit (4 or 8).
   - **Shadows**: Extract shadow values as `{ elevation, offset_x, offset_y, blur, spread, color, opacity }` tuples. No quantization — preserve as observed. Classify elevation tier: sm, md, lg, xl.
   - **Border Radius**: Snap to: 0, 2, 4, 6, 8, 12, 16, 24, 32, 9999 (full round). Identify which tier is used for small elements (badges, chips), medium elements (cards, inputs), and large elements (modals, containers).
   - **Opacity**: List observed opacity values used for overlays, disabled states, or decorative effects.
   - **Aesthetic**: Write a 2-3 sentence vibe description in present tense. Assign 4-8 personality tags (single words: minimal, bold, playful, corporate, elegant, etc.). Classify density and tone.

3. **What to Extract — Visual References** section:
   - **Colors**: Extract the dominant color palette only (3-7 colors). Assign roles as dominant/accent/surface/neutral based on area coverage.
   - **Aesthetic**: Write a vibe description and personality tags as above. These are the primary value of visual references.
   - **Everything else**: Set typography, spacing, shadows, border_radius, and opacity_scale to `null`. Visual references do not produce structural tokens.

4. **Quantization Rules** section (reference table):
   - Spacing grid: 4, 8, 12, 16, 20, 24, 32, 40, 48, 64, 80, 96, 128
   - Type scale: 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 28, 32, 36, 40, 48, 56, 64, 72, 80, 96
   - Border radius: 0, 2, 4, 6, 8, 12, 16, 24, 32, 9999
   - Shadows: no quantization
   - Colors: no hex rounding — infer intent

5. **Confidence Assessment** section:
   - `high`: Clear, high-resolution screenshot with visible UI patterns or vivid visual reference
   - `medium`: Partially obscured, low resolution, or small area visible
   - `low`: Very small, heavily cropped, or extremely blurry — findings are speculative

6. **Semantic Color Assignment** section listing the full taxonomy:
   - action.primary, action.secondary, action.destructive
   - surface.default, surface.raised, surface.overlay, surface.inset
   - text.primary, text.secondary, text.muted, text.inverse, text.link
   - border.default, border.focus
   - feedback.success, feedback.error, feedback.warning, feedback.info
   - For each, provide both light and dark theme assignments. If the screenshot is light-themed, infer dark-theme equivalents. If dark-themed, infer light-theme equivalents. Mark inferred values with a confidence note.

**File 2: `analysis-findings-schema.md`** — Human-readable spec. Must contain:

1. **Overview** explaining this is the output contract for the analysis agent — one document per input image.

2. **Field Reference** section with a table describing every field, its type, whether required, and its purpose. Group by: root fields, colors, typography, spacing, shadows, border_radius, opacity_scale, aesthetic.

3. **Fill-In Template** section containing the exact JSON structure the agent must fill in, with placeholder values and inline comments. This template must match the JSON Schema exactly. Use the template from the research document as the starting point, expanding it to include ALL fields (shadows, border_radius, opacity_scale, and the complete semantic color assignment taxonomy).

4. **Image Type Conditional Fields** section explaining that `visual_reference` images must set typography, spacing to `null` and only produce colors.primitive_palette and aesthetic.

5. **Example Outputs** section with two complete examples: one for a `ui_screenshot` and one for a `visual_reference`.
  </action>
  <verify>
    Both files exist at the specified paths. The rubric contains all 6 sections (Image Classification, What to Extract — UI Screenshots, What to Extract — Visual References, Quantization Rules, Confidence Assessment, Semantic Color Assignment). The findings spec contains a Field Reference table, a Fill-In Template, an Image Type Conditional Fields section, and two Example Outputs. The fill-in template JSON is valid JSON (test with a JSON parser after stripping comments).
  </verify>
  <done>
    The extraction rubric defines exactly what the analyzer must look for in each image type, with explicit quantization rules for every token category. The analysis findings spec provides a complete field reference and a fill-in JSON template that matches the JSON Schema.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create analysis findings JSON Schema 2020-12</name>
  <files>
    skills/dsys/schemas/analysis-findings.schema.json
  </files>
  <action>
Create `skills/dsys/schemas/analysis-findings.schema.json` — a valid JSON Schema 2020-12 document.

Use the schema from the research document as the starting point (it already has the `$schema`, `title`, `required` array, and most `properties`). Ensure the following refinements:

1. **Root required fields**: `image_type`, `source_path`, `confidence`, `colors`, `typography`, `spacing`, `shadows`, `border_radius`, `opacity_scale`, `aesthetic`. All are always required (even if `null` for visual references).

2. **`image_type`**: `enum: ["ui_screenshot", "visual_reference"]`

3. **`colors` object**: Always required regardless of image_type (visual references still produce a palette).
   - `primitive_palette`: array of `{ hex, role, frequency }` objects. `hex` pattern: `^#[0-9A-Fa-f]{6}$`. `role` enum: `dominant`, `accent`, `surface`, `text`, `neutral`, `feedback`. `frequency` enum: `primary`, `secondary`, `tertiary`.
   - `semantic_assignments`: object with ALL 18 semantic color keys as required properties (action_primary, action_primary_dark, action_secondary, action_secondary_dark, action_destructive, action_destructive_dark, surface_default, surface_default_dark, surface_raised, surface_raised_dark, text_primary, text_primary_dark, text_muted, text_muted_dark, text_inverse, border_default, border_focus, feedback_success, feedback_error, feedback_warning, feedback_info). Each property type: `["string", "null"]` with pattern `^#[0-9A-Fa-f]{6}$` for string values. For `visual_reference` images, semantic_assignments values will be `null`.
   - `background_style`: enum `light`, `dark`, `unknown`

4. **`typography`**: Use `oneOf` with two schemas — when `image_type` is `ui_screenshot`, require an object with `font_families` (object with `sans`/`mono`/`display` as `["string", "null"]`), `type_scale` (array of numbers), `weight_usage` (object with string keys and string values describing usage), `line_height_pattern` (enum: tight/normal/relaxed/loose). When `image_type` is `visual_reference`, must be `null`. Implement this using a top-level `if/then/else` on `image_type` for the typography field — or more cleanly, define typography as `type: ["object", "null"]` with the object schema defined, and add a top-level `allOf` with `if/then` constraints that enforce `null` when `image_type` is `visual_reference`.

5. **`spacing`**: Same conditional pattern. Object with `base_unit` (enum: 4, 8), `scale` (array of numbers), `density` (enum: compact/comfortable/spacious). `null` for visual references.

6. **`shadows`**: `type: ["array", "null"]`. Items: object with required `elevation` (enum: sm/md/lg/xl), `offset_x`, `offset_y`, `blur`, `spread` (all numbers), `color` (string), `opacity` (number, min 0, max 1).

7. **`border_radius`**: `type: ["object", "null"]`. Properties: `sm`, `md`, `lg` as `["number", "null"]`, `full` as `["boolean", "null"]`.

8. **`opacity_scale`**: `type: ["array", "null"]`. Items: number, min 0, max 1.

9. **`aesthetic`**: Always required. Object with `vibe_description` (string), `personality_tags` (array of strings, minItems: 4, maxItems: 8), `density` (enum: compact/comfortable/spacious), `tone` (enum: minimal/expressive/corporate/playful/bold/elegant).

10. **Top-level `allOf` constraint**: Add an `if/then` that enforces: when `image_type` is `visual_reference`, `typography` must be `null` and `spacing` must be `null`.

Validate the final JSON by parsing it to ensure it is syntactically valid JSON.
  </action>
  <verify>
    The file exists and is valid JSON (parse with `node -e "JSON.parse(require('fs').readFileSync('skills/dsys/schemas/analysis-findings.schema.json', 'utf8'))"`). The schema contains `$schema: "https://json-schema.org/draft/2020-12/schema"`. The `required` array at root level contains all 10 fields. The `allOf` or `if/then` constraint enforces null typography and spacing for visual references.
  </verify>
  <done>
    A valid JSON Schema 2020-12 file exists that can validate any analysis findings output. It correctly distinguishes UI screenshots (full extraction) from visual references (colors + aesthetic only). All fields are required (never absent, use null for "not found").
  </done>
</task>

</tasks>

<verification>
1. All three files exist under `skills/dsys/`
2. The JSON Schema file is valid JSON
3. The rubric contains explicit quantization tables for spacing (4px grid), type scale, and border radius
4. The rubric defines both UI screenshot and visual reference extraction procedures
5. The findings spec contains a fill-in JSON template that matches the JSON Schema field-by-field
6. The JSON Schema uses `if/then` to enforce null fields for visual references
7. The semantic color taxonomy in the rubric, the findings spec template, and the JSON Schema all list the same 18 semantic color keys
</verification>

<success_criteria>
- The analysis findings JSON Schema validates correct UI screenshot output without errors
- The analysis findings JSON Schema validates correct visual reference output (with null typography/spacing) without errors
- The analysis findings JSON Schema rejects output missing any required field
- The extraction rubric specifies quantization rules for spacing, type sizes, border radius, and color intent inference
- The findings spec contains a complete fill-in template and two worked examples
</success_criteria>

<output>
After completion, create `.planning/phases/01-schema-contracts/01-01-SUMMARY.md`
</output>
