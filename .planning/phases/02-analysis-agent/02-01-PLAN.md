---
phase: 02-analysis-agent
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - skills/dsys/schemas/analysis-findings.schema.json
  - skills/dsys/references/analysis-findings-schema.md
  - skills/dsys/agents/analyzer.md
autonomous: true
requirements:
  - INPUT-01
  - INPUT-02
  - INPUT-03
  - EXTRACT-01
  - EXTRACT-02
  - EXTRACT-03
  - EXTRACT-04
  - EXTRACT-05
  - ORCH-02

must_haves:
  truths:
    - "A schema-conformant analyzer agent prompt exists that can be invoked by the orchestrator via Task"
    - "The agent validates image inputs before attempting extraction and returns actionable error messages"
    - "The agent fills the Phase 1 template with extracted values, not freeform prose"
    - "The agent writes its output to a caller-specified file path using the Write tool"
    - "The Phase 1 schema accepts rationale strings without breaking existing conformant documents"
  artifacts:
    - path: "skills/dsys/agents/analyzer.md"
      provides: "Per-image vision extraction agent prompt"
      min_lines: 200
    - path: "skills/dsys/schemas/analysis-findings.schema.json"
      provides: "Extended JSON Schema with rationale and partial_failure fields"
      contains: "rationale"
    - path: "skills/dsys/references/analysis-findings-schema.md"
      provides: "Updated human-readable spec with rationale field documentation"
      contains: "rationale"
  key_links:
    - from: "skills/dsys/agents/analyzer.md"
      to: "skills/dsys/references/analysis-rubric.md"
      via: "Verbatim embedding of extraction rubric"
      pattern: "Extraction Rubric"
    - from: "skills/dsys/agents/analyzer.md"
      to: "skills/dsys/references/analysis-findings-schema.md"
      via: "Verbatim embedding of fill-in templates"
      pattern: "image_type.*source_path.*confidence"
    - from: "skills/dsys/schemas/analysis-findings.schema.json"
      to: "skills/dsys/references/analysis-findings-schema.md"
      via: "Schema and spec must define identical fields"
      pattern: "rationale"
---

<objective>
Extend the Phase 1 analysis findings schema with rationale and partial-failure fields, then write the analyzer agent prompt that embeds the rubric and fill-in template to extract design tokens from a single screenshot.

Purpose: This is the core deliverable of Phase 2 — the Markdown agent prompt file that Claude uses to analyze a screenshot and produce structured findings JSON. The schema extension is a prerequisite so the agent can include rationale strings (locked decision) and signal partial extraction failures without breaking schema conformance.

Output: Three modified/created files — extended schema, updated spec, and the new analyzer agent prompt.
</objective>

<execution_context>
@/Users/james/.claude/get-shit-done/workflows/execute-plan.md
@/Users/james/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@.planning/phases/01-schema-contracts/01-01-SUMMARY.md
@.planning/phases/02-analysis-agent/02-CONTEXT.md
@.planning/phases/02-analysis-agent/02-RESEARCH.md

@skills/dsys/references/analysis-rubric.md
@skills/dsys/references/analysis-findings-schema.md
@skills/dsys/schemas/analysis-findings.schema.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend analysis findings schema with rationale and partial-failure fields</name>
  <files>
    skills/dsys/schemas/analysis-findings.schema.json
    skills/dsys/references/analysis-findings-schema.md
  </files>
  <action>
Add three optional fields to `analysis-findings.schema.json` at the root level (alongside the existing 10 required fields). These are NOT added to the `required` array — they are optional additions:

1. `rationale` — an object with string values, keyed by semantic assignment key name:
```json
"rationale": {
  "type": "object",
  "description": "Brief rationale strings for semantic color assignments, keyed by the semantic key name (e.g., action_primary). Explains why each role was assigned to help the synthesizer resolve conflicts.",
  "additionalProperties": { "type": "string" }
}
```

2. `partial_failure` — a boolean:
```json
"partial_failure": {
  "type": "boolean",
  "description": "true if some token categories could not be extracted and were set to null. false or absent if all categories were successfully extracted."
}
```

3. `failed_categories` — an array of strings:
```json
"failed_categories": {
  "type": "array",
  "items": { "type": "string" },
  "description": "Names of token categories that could not be extracted (e.g., ['typography', 'shadows']). Present only when partial_failure is true."
}
```

Then update `analysis-findings-schema.md` to document these three new fields:

1. Add a new section "### Rationale Object" after the Aesthetic Object section in the Field Reference, documenting the field with a table row showing type `object`, required `No`, and describing it as optional rationale strings for semantic color assignments.

2. Add "### Partial Failure Fields" documenting `partial_failure` (boolean, optional) and `failed_categories` (string array, optional).

3. Update BOTH fill-in templates (ui_screenshot and visual_reference) to include the `rationale` field. For ui_screenshot, show it populated:
```json
"rationale": {
  "action_primary": "Appears on all CTA buttons and the primary navigation highlight",
  "surface_default": "Page background: the lightest surface color covering most of the viewport"
}
```
For visual_reference, show `rationale` as an empty object `{}` (no semantic assignments to rationalize).

4. Do NOT add `partial_failure` or `failed_categories` to the fill-in templates — these are set programmatically by the agent when extraction partially fails, not pre-filled.

IMPORTANT: Verify that the existing Phase 1 example JSONs (SaaS dashboard, brand mood board) at the bottom of analysis-findings-schema.md remain valid against the updated schema. Since the new fields are optional (not in `required`), existing documents without them must still pass validation.

After making changes, validate the schema file is valid JSON by parsing it.
  </action>
  <verify>
Run: `cat skills/dsys/schemas/analysis-findings.schema.json | python3 -c "import sys,json; json.load(sys.stdin); print('Valid JSON')"` — must print "Valid JSON".

Grep for "rationale" in both files: must appear in both schema and spec.

Verify the `required` array in analysis-findings.schema.json still has exactly 10 entries (the original fields) — the new fields must NOT be in `required`.
  </verify>
  <done>
analysis-findings.schema.json has three new optional root-level properties (rationale, partial_failure, failed_categories). analysis-findings-schema.md documents all three fields and includes rationale in the fill-in templates. Existing Phase 1 examples remain schema-conformant because no new required fields were added.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write the analyzer agent prompt</name>
  <files>
    skills/dsys/agents/analyzer.md
  </files>
  <action>
Create `skills/dsys/agents/analyzer.md` — the per-image vision extraction agent. This file IS the prompt, not a document that becomes one. It will be invoked by the orchestrator via Task(agent: "skills/dsys/agents/analyzer.md", prompt: "...").

Structure the agent prompt in these exact sections, in this order:

**1. Agent Header**
```markdown
---
name: dsys-analyzer
description: Analyzes a single screenshot and produces a schema-conformant analysis findings JSON file. One agent instance per image — the orchestrator runs multiple in parallel.
tools: Read, Write
---
```

**2. Role** — One paragraph: "You are the dsys visual extraction agent. You analyze one screenshot and produce a schema-conformant analysis findings JSON file. You are one of N agents running in parallel — each handles a single image independently."

**3. Input** — Explain that the agent receives two values in its task prompt:
- `image_path`: Local file path to the screenshot to analyze
- `output_path`: Where to write the findings JSON (e.g., `.dsys/findings/screenshot-1.json`)

**4. Step 1: Validate Input** — Before anything else:
1. Check that `image_path` ends in `.png`, `.jpg`, `.jpeg`, or `.webp` (case-insensitive). If not: STOP and return exactly: `"Error: Unsupported format: {ext} (use PNG, JPG, or WebP)"`
2. Use the Read tool to load the file at `image_path`. If Read fails: STOP and return exactly: `"Error: File not found or unreadable: {image_path}"`

**5. Step 2: Pre-Analysis — Identify Content Boundary** — Before extracting tokens:
- Identify and mentally exclude: browser toolbars/address bars/bookmarks bars, OS status bars (time/battery/signal), device bezels/frames/mockup overlays
- Only analyze the app/site content within these boundaries
- This is a locked decision from CONTEXT.md

**6. Step 3: Classify the Image** — Use Section 1 of the Extraction Rubric (embedded below) to classify as `ui_screenshot` or `visual_reference`. When ambiguous, classify as `visual_reference`.

**7. Step 4: Extract Values** — Follow the embedded Extraction Rubric for the classified image type. Add these specific instructions that implement locked decisions from CONTEXT.md:

Color-specific rules (locked decisions):
- Do NOT snap hex values to nearest standard. Preserve exact observed color values. Let the synthesizer decide on quantization.
- Only extract colors that appear on functional UI elements (buttons, text, backgrounds, borders, icons). Ignore colors in illustrations, gradients, hero images, or decorative graphical elements.
- When the screenshot shows mixed light/dark areas (dark sidebar + light content), treat as one theme with varied surface colors — not multiple themes.

Typography and spacing:
- Apply quantization rules from Rubric Section 4 exactly (4px grid for spacing, standard type scale for font sizes, standard weights).

Ambiguity handling (locked decision):
- When a color or assignment is ambiguous, include BOTH the chosen value AND the alternative interpretation in the rationale string. Example: `"action_primary": "#3B82F6"` with rationale `"Blue used on all primary buttons. Could alternatively be border_focus given its appearance on focused inputs, but button usage is dominant."`

**8. Step 5: Fill the Output Template** — Fill the appropriate template below with extracted values. Include explicit rules:
- Use the JSON literal `null` (no quotes) for absent or unobservable values. WRONG: `"sans": "null"` — RIGHT: `"sans": null`
- Do not add fields not in the template (`additionalProperties: false` is enforced)
- Do not leave placeholder text — every `#RRGGBB`, `FontName or null`, and enum placeholder must be replaced
- All 21 semantic assignment keys must be present (use `null` for unobservable roles)

Then embed the TWO fill-in templates from `analysis-findings-schema.md` VERBATIM:
- The ui_screenshot template (including the new `rationale` field)
- The visual_reference template (including `rationale: {}`)

Add the `partial_failure` and `failed_categories` fields instruction: "If you could not extract some token categories (typography, spacing, shadows, border_radius, opacity_scale) and set them to null even though the image is a ui_screenshot, add `partial_failure: true` and `failed_categories: ["category_name", ...]` to the root object."

**9. Step 6: Self-Validate** — Before writing, check:
1. All 21 semantic assignment keys are present
2. No placeholder text remains (no `#RRGGBB`, no `FontName or null`)
3. `image_type` matches the classification from Step 3
4. For `visual_reference`: typography, spacing, shadows, border_radius, opacity_scale are all `null`
5. For `ui_screenshot`: typography and spacing are objects (not null)
6. All hex values match the pattern `#` followed by exactly 6 hex characters

**10. Step 7: Write Output** — Write the completed JSON to `output_path` using the Write tool. Ensure the parent directory exists (create `.dsys/findings/` if needed). Do not return until Write has completed successfully.

**11. Step 8: Return Summary** — Return exactly one line:
`"Analyzed {filename}: {image_type}, confidence={level}, {N} primitive colors, {M} semantic assignments filled"`

**12. Extraction Rubric** — Embed the COMPLETE content of `skills/dsys/references/analysis-rubric.md` VERBATIM as the final section. Copy it exactly — do not paraphrase, reorder, abbreviate, or extend it. This is a locked Phase 1 artifact.

Discretion decisions (from Claude's Discretion in CONTEXT.md):
- Semantic role assignment: Assert boldly with rationale. The rationale string makes choices auditable; the synthesizer can override. Do not leave semantic keys as null when a reasonable inference exists.
- Font identification: Report best guess with qualifier in rationale. Example: `"sans": "Inter"` with rationale noting "Strong resemblance to Inter; geometric sans, consistent weight. Could be Geist." This gives the synthesizer more to work with than null.
- Component-level patterns: Do NOT extract. Defer to Phase 3/4. The Phase 1 schema does not have fields for them, and adding fields would break `additionalProperties: false`.
- Output file path: Orchestrator-controlled (Option B). The agent writes to whatever `output_path` it receives — it does not hardcode `.dsys/`.

Verify the completed file:
- Contains the frontmatter with name, description, tools
- Contains all 8 steps in order
- Contains the full extraction rubric embedded verbatim (compare line count: original is 331 lines)
- Contains both fill-in templates from analysis-findings-schema.md
- Does not contain any code blocks that are "pseudo-code" — everything is literal JSON or literal prose instructions
  </action>
  <verify>
File exists: `ls skills/dsys/agents/analyzer.md` succeeds.

Line count: `wc -l skills/dsys/agents/analyzer.md` should be >= 450 lines (331 from rubric + ~120+ from agent framing and templates).

Key content checks:
- `grep -c "Step" skills/dsys/agents/analyzer.md` returns at least 8 (the 8 steps)
- `grep -c "semantic_assignments" skills/dsys/agents/analyzer.md` returns >= 2 (appears in both templates)
- `grep -c "action_primary" skills/dsys/agents/analyzer.md` returns >= 4 (appears in both templates + rationale + rubric)
- `grep "additionalProperties" skills/dsys/agents/analyzer.md` confirms the agent mentions this constraint
- `grep "Write tool" skills/dsys/agents/analyzer.md` confirms the write instruction
- `grep "Error:" skills/dsys/agents/analyzer.md` confirms error message format
  </verify>
  <done>
`skills/dsys/agents/analyzer.md` exists with all 8 ordered steps, both fill-in templates embedded verbatim from the updated spec, the complete extraction rubric embedded verbatim from Phase 1, input validation with actionable error messages, self-validation before write, and explicit Write tool instruction. The agent can be invoked by the orchestrator via Task with an image_path and output_path.
  </done>
</task>

</tasks>

<verification>
1. `skills/dsys/agents/analyzer.md` exists and is >= 450 lines
2. `skills/dsys/schemas/analysis-findings.schema.json` is valid JSON with rationale, partial_failure, and failed_categories properties
3. `skills/dsys/references/analysis-findings-schema.md` documents all three new fields and includes rationale in fill-in templates
4. The agent prompt embeds the extraction rubric verbatim (diff the rubric section against the original file — they must match)
5. The agent prompt embeds both fill-in templates (ui_screenshot and visual_reference)
6. The agent prompt has input validation with two error message formats
7. The agent prompt has a self-validation step before writing output
8. The schema's `required` array still has exactly 10 entries (no new required fields)
</verification>

<success_criteria>
- A single Markdown agent file exists at `skills/dsys/agents/analyzer.md` that can be invoked by the orchestrator to analyze one screenshot
- The agent validates inputs, extracts tokens following the Phase 1 rubric, fills the Phase 1 template, self-validates, writes output, and returns a summary
- The schema accepts the new optional rationale field without breaking existing conformant documents
- All locked decisions from CONTEXT.md are implemented: exact color preservation, decorative color exclusion, mixed light/dark handling, rationale strings, actionable error messages, partial results as null with failed_categories
</success_criteria>

<output>
After completion, create `.planning/phases/02-analysis-agent/02-01-SUMMARY.md`
</output>
